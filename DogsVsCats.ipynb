{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eshan/anaconda3/envs/newenvt/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras import backend as K\n",
    "from keras.models import load_model\n",
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "nb_train_samples = 1600 # total no. of training examples\n",
    "nb_validation_samples = 400 # total np. of validation examples\n",
    "epochs = 50\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "if K.image_data_format() == 'channels_first':\n",
    "    input_shape = (3, img_width, img_height)\n",
    "else:\n",
    "    input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), input_shape=input_shape))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1))\n",
    "model.add(Activation('sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', # or categorical_crossentropy\n",
    "              optimizer='rmsprop',# or adagrad\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "    rescale=1. / 255,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is the augmentation configuration we will use for testing:\n",
    "# only rescaling\n",
    "test_datagen = ImageDataGenerator(rescale=1. / 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 1600 images belonging to 2 classes.\n",
      "{'dogs': 1, 'cats': 0}\n"
     ]
    }
   ],
   "source": [
    "train_generator = train_datagen.flow_from_directory(\n",
    "    train_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')\n",
    "\n",
    "print(train_generator.class_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 200 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "validation_generator = test_datagen.flow_from_directory(\n",
    "    validation_data_dir,\n",
    "    target_size=(img_width, img_height),\n",
    "    batch_size=batch_size,\n",
    "    class_mode='binary')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "100/100 [==============================] - 51s 512ms/step - loss: 0.7312 - acc: 0.4931 - val_loss: 0.6893 - val_acc: 0.5663\n",
      "Epoch 2/50\n",
      "100/100 [==============================] - 49s 485ms/step - loss: 0.6996 - acc: 0.5381 - val_loss: 0.6797 - val_acc: 0.5781\n",
      "Epoch 3/50\n",
      "100/100 [==============================] - 48s 484ms/step - loss: 0.7030 - acc: 0.5850 - val_loss: 0.6409 - val_acc: 0.5885\n",
      "Epoch 4/50\n",
      "100/100 [==============================] - 48s 484ms/step - loss: 0.6602 - acc: 0.6044 - val_loss: 0.6276 - val_acc: 0.6250\n",
      "Epoch 5/50\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 0.6468 - acc: 0.6363 - val_loss: 0.6527 - val_acc: 0.6641\n",
      "Epoch 6/50\n",
      "100/100 [==============================] - 49s 488ms/step - loss: 0.6297 - acc: 0.6838 - val_loss: 0.5827 - val_acc: 0.7344\n",
      "Epoch 7/50\n",
      "100/100 [==============================] - 49s 492ms/step - loss: 0.6241 - acc: 0.6787 - val_loss: 0.5646 - val_acc: 0.7318\n",
      "Epoch 8/50\n",
      "100/100 [==============================] - 50s 496ms/step - loss: 0.6066 - acc: 0.6762 - val_loss: 0.5978 - val_acc: 0.7266\n",
      "Epoch 9/50\n",
      "100/100 [==============================] - 50s 495ms/step - loss: 0.5949 - acc: 0.6925 - val_loss: 0.5570 - val_acc: 0.7396\n",
      "Epoch 10/50\n",
      "100/100 [==============================] - 50s 497ms/step - loss: 0.5697 - acc: 0.7113 - val_loss: 0.5360 - val_acc: 0.7578\n",
      "Epoch 11/50\n",
      "100/100 [==============================] - 50s 496ms/step - loss: 0.5803 - acc: 0.7125 - val_loss: 0.5457 - val_acc: 0.7266\n",
      "Epoch 12/50\n",
      "100/100 [==============================] - 50s 495ms/step - loss: 0.5632 - acc: 0.7131 - val_loss: 0.5747 - val_acc: 0.7526\n",
      "Epoch 13/50\n",
      "100/100 [==============================] - 2017s 20s/step - loss: 0.5621 - acc: 0.7375 - val_loss: 0.5816 - val_acc: 0.7396\n",
      "Epoch 14/50\n",
      "100/100 [==============================] - 52s 523ms/step - loss: 0.5574 - acc: 0.7269 - val_loss: 0.5666 - val_acc: 0.6990\n",
      "Epoch 15/50\n",
      "100/100 [==============================] - 49s 487ms/step - loss: 0.5253 - acc: 0.7512 - val_loss: 0.6025 - val_acc: 0.7370\n",
      "Epoch 16/50\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 0.5577 - acc: 0.7344 - val_loss: 0.5516 - val_acc: 0.7448\n",
      "Epoch 17/50\n",
      "100/100 [==============================] - 49s 485ms/step - loss: 0.5468 - acc: 0.7525 - val_loss: 0.5919 - val_acc: 0.7552\n",
      "Epoch 18/50\n",
      "100/100 [==============================] - 48s 485ms/step - loss: 0.5417 - acc: 0.7512 - val_loss: 0.6417 - val_acc: 0.6745\n",
      "Epoch 19/50\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 0.5115 - acc: 0.7519 - val_loss: 0.6763 - val_acc: 0.6823\n",
      "Epoch 20/50\n",
      "100/100 [==============================] - 49s 490ms/step - loss: 0.5230 - acc: 0.7537 - val_loss: 0.7509 - val_acc: 0.6875\n",
      "Epoch 21/50\n",
      "100/100 [==============================] - 48s 484ms/step - loss: 0.5195 - acc: 0.7613 - val_loss: 0.5734 - val_acc: 0.7448\n",
      "Epoch 22/50\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 0.5044 - acc: 0.7756 - val_loss: 0.6370 - val_acc: 0.7396\n",
      "Epoch 23/50\n",
      "100/100 [==============================] - 62s 624ms/step - loss: 0.4917 - acc: 0.7744 - val_loss: 0.5824 - val_acc: 0.7266\n",
      "Epoch 24/50\n",
      "100/100 [==============================] - 55s 551ms/step - loss: 0.5005 - acc: 0.7694 - val_loss: 0.6023 - val_acc: 0.7135\n",
      "Epoch 25/50\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 0.5083 - acc: 0.7856 - val_loss: 0.5723 - val_acc: 0.7188\n",
      "Epoch 26/50\n",
      "100/100 [==============================] - 48s 484ms/step - loss: 0.4987 - acc: 0.7719 - val_loss: 0.5247 - val_acc: 0.7891\n",
      "Epoch 27/50\n",
      "100/100 [==============================] - 48s 483ms/step - loss: 0.4817 - acc: 0.7750 - val_loss: 0.5758 - val_acc: 0.7321\n",
      "Epoch 28/50\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 0.4850 - acc: 0.7769 - val_loss: 0.5871 - val_acc: 0.7839\n",
      "Epoch 29/50\n",
      "100/100 [==============================] - 48s 484ms/step - loss: 0.4658 - acc: 0.7819 - val_loss: 0.5558 - val_acc: 0.7995\n",
      "Epoch 30/50\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 0.4815 - acc: 0.7800 - val_loss: 0.6538 - val_acc: 0.7109\n",
      "Epoch 31/50\n",
      "100/100 [==============================] - 48s 481ms/step - loss: 0.4886 - acc: 0.8044 - val_loss: 0.5377 - val_acc: 0.7812\n",
      "Epoch 32/50\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 0.4688 - acc: 0.7875 - val_loss: 0.5127 - val_acc: 0.7839\n",
      "Epoch 33/50\n",
      "100/100 [==============================] - 48s 485ms/step - loss: 0.4441 - acc: 0.7969 - val_loss: 0.5399 - val_acc: 0.7839\n",
      "Epoch 34/50\n",
      "100/100 [==============================] - 48s 484ms/step - loss: 0.4818 - acc: 0.7856 - val_loss: 0.5079 - val_acc: 0.8021\n",
      "Epoch 35/50\n",
      "100/100 [==============================] - 48s 485ms/step - loss: 0.4858 - acc: 0.7719 - val_loss: 0.6174 - val_acc: 0.7552\n",
      "Epoch 36/50\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 0.4605 - acc: 0.7956 - val_loss: 0.6903 - val_acc: 0.7891\n",
      "Epoch 37/50\n",
      "100/100 [==============================] - 1352s 14s/step - loss: 0.4895 - acc: 0.7750 - val_loss: 0.6255 - val_acc: 0.7526\n",
      "Epoch 38/50\n",
      "100/100 [==============================] - 49s 492ms/step - loss: 0.4625 - acc: 0.7944 - val_loss: 0.5351 - val_acc: 0.7656\n",
      "Epoch 39/50\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 0.4538 - acc: 0.8025 - val_loss: 0.5471 - val_acc: 0.7891\n",
      "Epoch 40/50\n",
      "100/100 [==============================] - 49s 486ms/step - loss: 0.4591 - acc: 0.8106 - val_loss: 0.5769 - val_acc: 0.7832\n",
      "Epoch 41/50\n",
      "100/100 [==============================] - 48s 483ms/step - loss: 0.4579 - acc: 0.7938 - val_loss: 1.6592 - val_acc: 0.6484\n",
      "Epoch 42/50\n",
      "100/100 [==============================] - 49s 485ms/step - loss: 0.4366 - acc: 0.8069 - val_loss: 0.6068 - val_acc: 0.7760\n",
      "Epoch 43/50\n",
      "100/100 [==============================] - 48s 481ms/step - loss: 0.4748 - acc: 0.8006 - val_loss: 0.6513 - val_acc: 0.7318\n",
      "Epoch 44/50\n",
      "100/100 [==============================] - 48s 481ms/step - loss: 0.4735 - acc: 0.8037 - val_loss: 0.5128 - val_acc: 0.7708\n",
      "Epoch 45/50\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 0.4860 - acc: 0.8056 - val_loss: 0.5869 - val_acc: 0.7891\n",
      "Epoch 46/50\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 0.4528 - acc: 0.8125 - val_loss: 0.5559 - val_acc: 0.7448\n",
      "Epoch 47/50\n",
      "100/100 [==============================] - 48s 482ms/step - loss: 0.4557 - acc: 0.7963 - val_loss: 0.6568 - val_acc: 0.7422\n",
      "Epoch 48/50\n",
      "100/100 [==============================] - 48s 479ms/step - loss: 0.4838 - acc: 0.7900 - val_loss: 0.5672 - val_acc: 0.7552\n",
      "Epoch 49/50\n",
      "100/100 [==============================] - 48s 480ms/step - loss: 0.4693 - acc: 0.7981 - val_loss: 0.5952 - val_acc: 0.7474\n",
      "Epoch 50/50\n",
      "100/100 [==============================] - 48s 484ms/step - loss: 0.4707 - acc: 0.8006 - val_loss: 0.5411 - val_acc: 0.7500\n"
     ]
    }
   ],
   "source": [
    "model.fit_generator(\n",
    "    train_generator,\n",
    "    steps_per_epoch=nb_train_samples // batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=nb_validation_samples // batch_size)\n",
    "\n",
    "model.save('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['8.jpg', '4.jpg', '5.jpg', '7.jpg', '6.jpg', '2.jpg', '3.jpg', '1.jpg']\n",
      "8.jpg: dog\n",
      "4.jpg: cat\n",
      "5.jpg: dog\n",
      "7.jpg: cat\n",
      "6.jpg: cat\n",
      "2.jpg: dog\n",
      "3.jpg: cat\n",
      "1.jpg: dog\n",
      "Total Dogs : 4\n",
      "Total Cats : 4\n"
     ]
    }
   ],
   "source": [
    "# dimensions of our images\n",
    "img_width, img_height = 150, 150\n",
    "\n",
    "# load the model we saved\n",
    "model = load_model('model.h5')\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mypath = \"predict/\"  # Location of the images to be predicted\n",
    "onlyfiles = [f for f in listdir(mypath) if isfile(join(mypath, f))]\n",
    "print(onlyfiles)\n",
    "# predicting images\n",
    "dog_counter = 0 \n",
    "cat_counter  = 0\n",
    "for file in onlyfiles:\n",
    "    img = image.load_img(mypath+file, target_size=(img_width, img_height))\n",
    "    x = image.img_to_array(img)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    \n",
    "    images = np.vstack([x])\n",
    "    classes = model.predict_classes(images, batch_size=10)\n",
    "    classes = classes[0][0]\n",
    "    \n",
    "    if classes == 0:\n",
    "        print(file + \": \" + 'cat')\n",
    "        cat_counter += 1\n",
    "    else:\n",
    "        print(file + \": \" + 'dog')\n",
    "        dog_counter += 1\n",
    "print(\"Total Dogs :\",dog_counter)\n",
    "print(\"Total Cats :\",cat_counter)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
